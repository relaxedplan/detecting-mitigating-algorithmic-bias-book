{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions for this LiveProject\n",
    "\n",
    " - Detecting and mitigating bias in ML models can be overwhelming. Many types of unwanted bias are so deeply rooted that the only way to mitigate them is societal. It's helpful to remember that you are not alone - many people are working towards this level of change, at a local, national and international level.\n",
    "\n",
    " - Explainability and interpretability methods are versatile and empower you and others to detect and mitigate algorithmic bias in data. By explaining to stakeholders and subjects what your model is doing, you create space for commentary and a broader range of perspectives which can alert you to all kinds of bias.\n",
    " \n",
    " - Metrics for detecting algorithmic bias have a valuable place in the process. They can quantify certain kinds of harms and justify mitigation actions. However, for most metrics there is no legal or technical consensus for a threshold dividing bias worth mitigating from bias not worth mitigating. You and your team will have to decide on your own. These decisions will be deeply contextual and in real-world scenarios you will have context not available in a LiveProject.\n",
    " \n",
    " - Methods for mitigating algorithmic bias are especially exciting in a group fairness context and there are a wide variety to chose from. The choice of method (and metrics to choose between methods) matter and should be decided with respect to your problem.\n",
    " \n",
    " - Often there will be barriers to bias detection and mitigation in data, but those barriers can sometimes be surmounted. In the example we covered here (when the proteced class is missing), we can work around the challenge but we are reliant on an accurate proxy model which may not always be available. \n",
    "\n",
    " - Domain knowledge and experience with your data will improve your ability to detect and mitigate bias in ML models. This project was focused on health data. What you have learned in this LiveProject will certainly carry over to other domains, but it is useful to think about particular biases, metrics, methods, tasks and users which are specific to your specific domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
