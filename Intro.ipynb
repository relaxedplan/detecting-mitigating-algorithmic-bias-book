{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this LiveProject\n",
    "\n",
    "In this LiveProject, you will assume the role of a data scientist at the Washington DC branch of the World Health Organization tasked with running algorithmic bias audits on models in a healthcare context. \n",
    "\n",
    "The WHO is a specialized agency of the United Nations, which organizes global co-operation on intersectional approaches to health. Key WHO issue areas at play in this LiveProject are the monitoring and management of epidemics, social determinants of health, and access to essential medicines and health products.\n",
    "\n",
    "As machine learning models have become more powerful and more ubiquitous, decision-making which once took up human resources has been automated away. Machine learning models can contain powerful biases, which are often undesirable in a health context. Detecting and mitigating unwanted forms of algorithmic bias in machine learning models is a continuing challenge which you are called on to address as part of the WHO’s data strategy.\n",
    "\n",
    "The universe of bias in artificial intelligence is vast, and what is unwanted bias is highly context-dependent. The nuances and history of algorithmic bias have led to an emerging best practice which calls on data scientists to  look for bias within the task, data and the model itself, but also the process of creation and deployment, the subjects, uses, and ownership, all within the model’s social and geopolitical context.\n",
    "\n",
    "This LiveProject trains data scientists on state-of-the-art algorithmic tools for bias detection and mitigation through four milestones. These algorithmic tools are not rubber stamps and their limitations as well as important non-algorithmic questions for bias detection are incorporated into the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques Employed\n",
    "Listed under the bullets are the Python libraries for the technique.\n",
    "\n",
    "Loading and analysing tabular data\n",
    "  - pandas\n",
    "\n",
    "Building simple machine learning models which can be interpreted or debiased\n",
    "\n",
    "  - scikit-learn\n",
    "  - lightgbm\n",
    "\n",
    "Interpreting the underlying logic behind a particular prediction or ML model\n",
    "  - SHAP\n",
    "  - AIF360\n",
    "\n",
    "Modifying the algorithm to mitigate unwanted bias\n",
    "  - AIF360\n",
    "\n",
    "Resources are provided for working with these techniques/libraries both as embedded in Manning liveBooks and as links to external documentation. On the job, you will often be given partial information and must learn how to seek out relevant resources on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project outline\n",
    "The project is broken into four parts.\n",
    "\n",
    "The first milestone, on explainability, guides you through SHAP, a package which can be used generally to explain model predictions, and is additionally useful here for empowering model stakeholders and subjects to understand and critique the model for bias.\n",
    "\n",
    "The second milestone explores the universe of bias in machine learning models and demoes the algorithmic tools explored the third and fourth milestones. \n",
    "\n",
    "The third milestone guides you through AIF-360, a package for detecting and mitigating algorithmic bias which causes allocation harm across groups. By the end of this milestone you will be able to use the package to not only detect algorithmic bias across groups but also alter models to mitigate that bias.\n",
    "\n",
    "The fourth milestone guides you through a problem where bias along racial lines is suspected, and you need to measure it, but with an additional challenge - racial membership is not available in the data. We mitigate this challenge using proxy models and data combination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "The liveProject is for intermediate Python programmers with experience in data science. The focus of this course is not to teach modelling but to show how models can be audited for bias, and the ways that bias can be mitigated. \n",
    "\n",
    "We will not focus on building highly accurate models (eg there is no hyperparameter tuning). To begin this liveProject, you will need to be familiar with:\n",
    "\n",
    " - Basics of pandas\n",
    " - Basics of scikit-learn\n",
    " - Basics of Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python libraries and setup\n",
    "This LiveProject uses Python 3.7. It is recommended to use the Anaconda distribution of Python and conda for managing the libraries.\n",
    "\n",
    "The following Python libraries will be utilized in this project. Again, you don’t need working experience with all of these, as you can pick up the basics by reading documentation and putting them to use.\n",
    "\n",
    "Loading and analysing tabular data\n",
    "  - pandas\n",
    "\n",
    "Building simple machine learning models which can be interpreted or debiased\n",
    "\n",
    "  - scikit-learn\n",
    "  - lightgbm\n",
    "\n",
    "Interpreting the underlying logic behind a particular prediction or ML model\n",
    "  - SHAP\n",
    "  - AIF360\n",
    "\n",
    "Detecting and mitigating unwanted bias\n",
    "  - AIF360\n",
    "  \n",
    "Plotting\n",
    "  - matplotlib\n",
    "  - seaborn\n",
    "\n",
    "\n",
    "To install these libraries, clone the base Git repository to your computer and run conda env create -f environment.yml from the root project directory (assuming you are using conda).\n",
    "Once the virtual environment is created, you can activate it with conda activate bias-book and run a Jupyter Notebook with jupyter notebook.\n",
    "Any additional libraries you need can be installed with conda install “library.” \n",
    "\n",
    "Resources and tutorials are provided throughout the project. Feel free to use any resources you can find to complete the project.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
