{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective:\n",
    "\n",
    " - Become familiar with origins of unwanted bias, ways to measure unwanted bias, and ways to mitigate unwanted bias.\n",
    "\n",
    "#### Workflow:\n",
    "\n",
    " - Take the \"Fairness\" portion of the Google Machine Leaning Crash Course. You may skip the \"programming exercise\", since we will cover a similar exercise in more depth in the next milestone.\n",
    " - Take the AIF360 demo, on each of the datasets at https://aif360.mybluemix.net/data. Pay particular attention how bias is measured\n",
    "  - At the \"check\" phase, review the definition of each bias metric\n",
    "  - Taking the Compas dataset as an example, note who will lose out if the unwanted bias is not mitigated, and the real-world impact that can have.\n",
    "  - Taking the German Credit Scoring dataset as an example, test each mitigation approach. Choose the mitigation approach that removes the most bias, and take notes on how it works.\n",
    " - Read and review the following two articles, taking special note of different ways that bias can arise: https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb, https://www.toptal.com/artificial-intelligence/mitigating-ai-bias\n",
    " - Read and review \"Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms\", and reflect on the importance of organizational structure in mitigating bias, including diversity-in-design.\n",
    " - Take quiz to test your knowledge\n",
    "\n",
    "\n",
    "#### Importance to Project:\n",
    "\n",
    " - A key aspect of this project is detecting and mitigating unwanted bias. These resources introduce learners to the key algorithmic components to detecting bias (bias metrics) and key algorithmic components in mitigating bias (debiasing methods).\n",
    " \n",
    "#### Resources:\n",
    "\n",
    "Short reads:\n",
    "\n",
    "https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias (This lists some common types of bias which arise when developing machine learning models.)\n",
    "\n",
    "https://aif360.mybluemix.net/data (This demo of AIF360, a debiasing tool, shows the detection of unwanted biases, and demonstrates how data or model manipulation can improve fairness for certain groups.)\n",
    "\n",
    "https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/ (Useful document summarizing bias mitigation and best practices at an individual, team, and organizational level)\n",
    "\n",
    "https://dssg.github.io/aequitas/metrics.html (document summarizing relevant metrics for evaluating bias mathematically) \n",
    "\n",
    "https://www.toptal.com/artificial-intelligence/mitigating-ai-bias (reviews some historical cases of AI bias, discusses in brief some detection and mitigation tools, discusses in brief some legal issues)\n",
    "\n",
    "http://www.datasciencepublicpolicy.org/projects/aequitas/ (a bias detection toolkit. We don't use this in the liveProject, but it is useful to be aware of)\n",
    "\n",
    "Long reads:\n",
    "\n",
    "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb (An end-to-end fairness tutorial)\n",
    "\n",
    "https://sites.google.com/view/fatecv-tutorial/schedule?authuser=0 (A 3-part seminar reviewing algorithmic bias in computer vision. This seminar is particularly important because it describes how historical and societal context can influence the design and impact of machine learning models, to the detriment of historically marginalized groups.\n",
    "\n",
    "http://www.californialawreview.org/wp-content/uploads/2016/06/2Barocas-Selbst.pdf (A paper reviewing the challenges algorithmic bias poses to US Discrimination law)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.1 - Take the \"Fairness\" portion of the Google Machine Leaning Crash Course. You may skip the \"programming exercise\", since we will cover a similar exercise in more depth in the next milestone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.2 - Take the AIF360 demo, on each of the datasets at https://aif360.mybluemix.net/data. Pay particular attention how bias is measured\n",
    "  - At the \"check\" phase, review the definition of each bias metric\n",
    "  - Taking the Compas dataset as an example, note who will lose out if the unwanted bias is not mitigated, and the real-world impact that can have.\n",
    "  - Taking the German Credit Scoring dataset as an example, test each mitigation approach. Choose the mitigation approach that removes the most bias, and take notes on how it works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 2.3 - Read and review the following two articles, taking special note of different ways that bias can arise: https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb, https://www.toptal.com/artificial-intelligence/mitigating-ai-bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 2.4 - Read and review \"Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms\", and reflect on the importance of organizational structure in mitigating bias, including diversity-in-design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 2.5 - take the quiz to test your knowledge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
