{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective:\n",
    "\n",
    " - Become familiar with ways to measure unwanted bias, \n",
    "\n",
    "#### Workflow:\n",
    "\n",
    " - Take the \"Fairness\" portion of the Google Machine Leaning Crash Course. You may skip the \"programming exercise\", since we will cover a similar exercise in more depth in the next milestone.\n",
    " - Take the AIF360 demo, on each of the datasets at https://aif360.mybluemix.net/data. Pay particular attention how bias is measured\n",
    " - At the \"check\" phase, review the definition of each bias metric\n",
    " - Taking the Compas dataset as an example, note who will lose out if the unwanted bias is not mitigated, and the real-world impact that can have.\n",
    " - Taking the German Credit Scoring dataset as an example, test each mitigation approach. Choose the mitigation approach that removes the most bias, and take notes on how it works.\n",
    " - Read and review the following two articles, taking special note of different ways that bias can arise: https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb, https://www.toptal.com/artificial-intelligence/mitigating-ai-bias\n",
    " - Read article \"Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms\", and reflect on the importance of organizational structure in mitigating bias, including diversity-in-design.\n",
    "\n",
    "\n",
    "#### Importance to Project:\n",
    "\n",
    " - A key aspect of this project is detecting and mitigating unwanted bias. These resources introduce learners to the key algorithmic components to detecting bias (bias metrics) and key algorithmic components in mitigating bias (debiasing methods).\n",
    " \n",
    "#### Resources:\n",
    "https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias\n",
    "\n",
    "https://aif360.mybluemix.net/data\n",
    "\n",
    "https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/\n",
    "\n",
    "https://dssg.github.io/aequitas/metrics.html\n",
    "\n",
    "https://www.toptal.com/artificial-intelligence/mitigating-ai-bias\n",
    "\n",
    "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb\n",
    "\n",
    "https://www.toptal.com/artificial-intelligence/mitigating-ai-bias\n",
    "\n",
    "http://www.datasciencepublicpolicy.org/projects/aequitas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 - Take the \"Fairness: Evaluating for Bias\" portion of the Google Machine Learning Crash Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 - take AIF360 demo. Pay particular attention to how bias is measured. At the \"check\" phase, review the definition of each bias impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 - Taking the Compas dataset as an example, explain who will lose out if the unwanted bias is not mitigated, and the real-world impact that can have.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 - Taking the German Credit Scoring dataset as an example, test each mitigation approach. Choose the mitigation approach that removes the most bias, and explain how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 - Take the attached quiz. You will need to closely follow the resources to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
